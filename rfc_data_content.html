<h1 id="request-for-comment-content-for-μseismic-data-exchange">Request For Comment — Content for μSeismic Data Exchange</h1>
<h2 id="introduction">Introduction</h2>
<h3 id="purpose">Purpose</h3>
<p>The purpose of this document is to invite comments on a suggested format to allow for standardized and consistent access to μseismic data collected by mine μseismic monitoring systems. This format aims to enable a seamless and lossless exchange between different platforms. The objective of the proposed standard <strong>does not</strong> concern how seismic data are <strong>internally managed</strong> within each proprietary platform, although the capability of the present format would be suited for that purpose, it only focuses on how the data are exchanged.</p>
<p>The proposed standard applies to a wide range of data including triggered event, continuous recording, and DAS monitoring. It allows for different data types to be combined.</p>
<p>Access to the μseismic data is inconsistent among various vendors, and occasionally within different implementations by the same vendor. Variations arise from site to site, often driven by third-party requirements. Such inconsistencies lead to inefficiencies, complicating the integration of various systems that offer complementary products and services, and making data usage unnecessarily challenging.</p>
<p>In light of recent advancements in μseismic monitoring technology, the imperative for a standardized format becomes even more salient. The microseismic monitoring landscape is evolving, marked by the deployment of increasingly expansive monitoring systems. These systems, given their extensive scale, inherently produce voluminous data sets. Furthermore, the incursion of Distributed Acoustic Sensing (DAS) in mining adds another layer of complexity, both in terms of data volume and diversity. DAS, with its high spatial resolution and continuous monitoring capability, generates data at an unprecedented scale. A robust and standardized format is crucial to efficiently manage, process, and interpret these burgeoning data streams, ensuring that the rich information they provide can be harnessed effectively and cohesively.</p>
<p>This document proposes a file structure and format. At this stage, we seek alignment on the content of the information transferred and consensus on the container format.</p>
<h3 id="scope">Scope</h3>
<p>With the increasing volume of μseismic data collected, especially in modern expansive monitoring systems and with technologies like Distributed Acoustic Sensing (DAS), there is a need for efficient management and handling of this data. The scope of this proposed standard is to define the content and nature of μseismic information provided to third parties and to suggest a format that facilitates efficient storage, retrieval, and exchange, of complete information required to further analyse the data.</p>
<p>Computational efficiency in storing and retrieving large volume of data that are prescribed by increasingly expansive system and the adoption of the DAS technology, is central. The ability to provide a storage mechanism flexible and extensible enough to package both triggered and continous data is another objective.</p>
<p>The standard focuses on the foundational elements and seismic information intrinsic to μseismic monitoring including:</p>
<ul>
<li><strong>Waveforms</strong> — This includes the raw, unprocessed waveform for both continuous and triggered data.</li>
<li><strong>Catalog Information</strong> — This covers event information derived from waveform data processing.</li>
<li><strong>Inventory or System Information</strong> — Details about the instruments (sensors and data acquisition modules) used in the data acquisition chain are included here, along with other critical data processing information, such as velocity, density, and attenuation values or models.</li>
</ul>
<h3 id="rationale">Rationale</h3>
<h4 id="need-for-a-new-standard">Need for a New Standard</h4>
<p>The increase in microseismic data, particularly from expansive monitoring systems and new technologies like Distributed Acoustic Sensing (DAS), underscores the pressing need for a more efficient and unified data format. Currently, the varied nature of microseismic data formats hinders streamlined integration and analysis, posing challenges in managing and deriving value dataset collected by in-mine monitoring system. The lossy and incoherent nature of current data exchange formats are hindering innovation and make the utilization of μseismic data unecessarily difficul. Given the critical importance of microseismic data in ensuring the safety and improving the operations of underground mining, establishing a standardized format and mechanism of echange becomes imperative. The propose standard objective is to facilitate more straightforward data access, efficient storage, and smoother data exchanges across different platforms for a variety of data types.</p>
<h4 id="goal">Goal</h4>
<p>The primary objective of this RFC is to introduce a proposed data content, packaging format, and naming conventions that are aimed at enhancing interoperability, consistency, and innovation within the sphere of microseismic monitoring. As we acknowledge the integral role of microseismic data in underground mining operations’ safety and efficiency, this proposal serves as a step forward in harmonizing and optimizing the way in which data is accessed, managed, and exchanged across diverse platforms in the industry.</p>
<p>To this end, this proposal seeks to:</p>
<ul>
<li><p><strong>Promote Universality</strong>: By implementing a unified format tailored specifically for microseismic monitoring systems, the intent is to transcend vendor-specific or third-party constraints, allowing seamless integration across a range of platforms.</p></li>
<li><p><strong>Ensure Scalability</strong>: Given the rising volume of data being generated by expansive microseismic monitoring systems, particularly with the advent of Distributed Acoustic Sensing (DAS) technology, the proposed format is designed to accommodate large datasets without compromising on efficiency or speed of data retrieval.</p></li>
<li><p><strong>Enhance Clarity and Coherence</strong>: Implementing a standardized naming convention ensures a structured approach to data management, reducing ambiguities and promoting swift, clear data identification and processing.</p></li>
<li><p><strong>Facilitate Innovation</strong>: With a consistent, standardized foundation in place, researchers, developers, and industry professionals will be better poised to innovate, iterate, and develop new tools, methodologies, and solutions that harness the full potential of microseismic data.</p></li>
</ul>
<p>In summary, the goal is to provide a robust framework that not only addresses the present challenges posed by varied data formats but also anticipates and caters to the evolving needs of the microseismic monitoring industry. Through this proposed standard, we endeavor to usher in an era of streamlined data access, management, and exchange that can truly capitalize on the advancements in microseismic monitoring technology.</p>
<h3 id="rfc-process-and-schedule">RFC Process and Schedule</h3>
<p>We propose the following RFC process that should lead to the standard adoption. It is unclear at this time where and by who the standard will be published.</p>
<h4 id="process">Process:</h4>
<ol type="1">
<li><strong>Drafting</strong>: Development of the initial RFC document.</li>
<li><strong>Publication</strong>: Making the RFC available for a wider audience for review and comment.</li>
<li><strong>Review</strong>: A period of review where stakeholders provide feedback.</li>
<li><strong>Revision</strong>: Updates to the RFC based on feedback received.</li>
<li><strong>Final Comment Period</strong>: A last opportunity for feedback before a the final standard is published.</li>
<li><strong>Adoption</strong>: Adoption of the RFC.</li>
<li><strong>Publication</strong>: If adopted, the Standard is officially published.</li>
<li><strong>Implementation</strong>: Introduction of the recommended practices or standards from the RFC.</li>
<li><strong>Review Cycle</strong>: Periodic reviews of the RFC’s effectiveness post-implementation.</li>
</ol>
<h4 id="schedule">Schedule:</h4>
<ul>
<li><ol type="1">
<li><strong>Drafting and Initial Publication</strong>: Completed as of 2023-10-20.</li>
</ol></li>
</ul>
<ol start="2" type="1">
<li><strong>Review</strong>: Given the complexities and the necessity to involve various stakeholders, we suggest allocating four months to the review. This will ensure that all participants have ample time to understand, discuss, and provide thoughtful feedback.
<ul>
<li><strong>Start</strong>: 2023-11</li>
<li><strong>End</strong>: 2023-03</li>
</ul></li>
<li><strong>Revision</strong>: Considering the extended review period and potential for substantial feedback, one months will be set aside for revisions.
<ul>
<li><strong>Start</strong>: 2023-03</li>
<li><strong>End</strong>: 2023-04</li>
</ul></li>
<li><strong>Final Comment Period</strong>: This phase allows stakeholders another chance to review the revised RFC and provide final comments. Two months seems reasonable for this step, given the extended timeline for other phases.
<ul>
<li><strong>Start</strong>: 2023-04</li>
<li><strong>End</strong>: 2023-06</li>
</ul></li>
<li><strong>Adoption</strong>: The adoption mechanism has to be determined. There is currently no body governing microseismic monitoring.
<ul>
<li><strong>Date</strong>: 2023-06</li>
</ul></li>
<li><strong>Official Publication</strong>: After finalizing the adoption, a week is allocated for any final edits, formatting, and dissemination of the standard.
<ul>
<li><strong>Date</strong>: 2023-07</li>
</ul></li>
<li><strong>Implementation and Review Cycle</strong>: As before, this is a longer-term step and its start would be dependent on the decisions made and the complexity of the implementation.
<ul>
<li><strong>Start</strong>: 2023-07</li>
<li><strong>Review Cycle</strong>: Every 6 months (or another interval that makes sense based on the nature of the standard and its implications)</li>
</ul></li>
</ol>
<h2 id="proposal">Proposal</h2>
<h3 id="overview">Overview</h3>
<p>Our proposal encompasses three categories of data: the waveforms, the catalog data, and the inventory and system information. It also concerns system metadata such as velocity models.</p>
<p>We propose using the <code>ASDF</code> format with a <code>.asdf</code> extension to store the waveforms, the catalog (QuakeML), and inventory (StationXML) information. The <code>ADSF</code> format provides a convenient and comprehensive mechanism to store the provenance and lineage information related to the data genesis and modification to provide traceability and data history. Note that the <code>ASDF</code> format also provides a convenient way to store auxiliary data that could, for instance, include:</p>
<ul>
<li><p><strong>Ambient Noise Correlations</strong>: Pre-computed cross-correlations between stations, which can be essential for techniques like ambient noise tomography.</p></li>
<li><p><strong>Instrument Response</strong>: Though typically part of the StationXML, having the actual instrument response curves stored as auxiliary data can facilitate more direct correction of the waveforms without referencing external databases.</p></li>
<li><p><strong>Rays and Ray Parameters from Ray Tracing</strong>: Storing detailed ray paths and relevant parameters is useful for higher order analyses such as travel time and attenuation tomography, and moment tensor inversion to name only those. By integrating these data directly within the <code>ASDF</code> format, researchers can achieve a holistic understanding of the seismic event and the underlying geophysical processes, ensuring that they have all pertinent information at their fingertips without resorting to supplementary datasets or computations.</p></li>
<li><p><strong>Velocity Information</strong>: If relevant the velocity and velocity model could be stored alongside the seismic data.</p></li>
<li><p><strong>Alternative location</strong>: Alternative locations obtain from statistical analyses including jacknife or Montecarlo associated, could provide benefit to correctly assess the system performance.</p></li>
<li><p><strong>Processing Logs</strong>: Detailed logs of processing steps performed on the data, which can be crucial for ensuring data quality and understanding potential issues or artifacts.</p></li>
</ul>
<p>To ensure interoperability, the information in the provided files must be consistent. The sensor naming convention shall remain consistent throughout. Additionally, the locations of sensors and events should be expressed using a unified coordinate system, which must also be used for grids, if applicable.</p>
<h3 id="why-asdf-format">Why <code>ASDF</code> format?</h3>
<p>The Adaptable Seismic Data Format (ASDF) was introduced in response to the need for an efficient and comprehensive format for seismic data storage and retrieval. Developed through collaborative research by experts in the seismology field, ASDF aims to address the complexities associated with managing diverse seismic datasets. The format has been designed with adaptability in mind, ensuring both ease of use and interoperability across various platforms. As a result of its well-structured architecture, ASDF has gained widespread acceptance within the seismology community.</p>
<p>The <code>ASDF</code> format was designed to efficiently store and access large-scale array-oriented scientific data. Its design addresses the challenges posed by cloud and distributed storage, allowing for concurrent reads and writes. The format shines in scenarios where data needs to be analyzed in chunks without loading the entire dataset into memory, making it particularly apt for multidimensional arrays. With built-in support for compression and chunking, ASDF facilitates rapid data access regardless of the storage backend, whether it’s file systems, object storage, or databases.</p>
<p>The ASDF (Adaptable Seismic Data Format) file structure is meticulously designed to cater to the specific needs of modern seismology. Central to its architecture is the seamless integration of seismic waveforms and associated metadata, ensuring the cohesiveness of data and information. The format organizes its content into two principal components: (1) the seismic waveforms, stored as time series data, and (2) the metadata, which incorporates station and event information using standardized formats such as StationXML and QuakeML. This harmonization ensures uniformity in the representation of seismic stations and earthquake event details. Processing histories, provenance details, as well as auxiliary data like adjoint sources and receiver functions, can also be embedded, further enhancing the format’s comprehensive nature. A distinguishing trait of ASDF is its optimization for parallel I/O operations, positioning it as a prime choice for high-performance computing environments. The principles, design considerations, and virtues of the ASDF architecture have been expansively documented in the Geophysical Journal International (Krischer et al., 2016) <a href="https://chat.openai.com/c/78d37cb0-1768-4534-8a30-dad9fe3d2f0c#user-content-fn-1%5E">1</a>.</p>
<p>By adopting <code>ASDF</code>, we can store data and metadata in formats closely aligned with those widely accepted by the seismology community. It’s feasible to encapsulate waveforms, event catalogs, and system information within a single container, enabling standalone usage. Additionally, the format can be tailored to accommodate variations in the information required for triggered and continuous data.</p>
<p>The benefits of using the <code>ASDF</code> format become particularly evident when considering the nature of waveform data. More broadly, the main benefit of employing the <code>ASDF</code> format to store seismic data and metadata include:</p>
<ol type="1">
<li><ol type="1">
<li><strong>Integrated Storage and Organization</strong>: ASDF is a comprehensive and well-defined format that seamlessly integrates seismological waveform data and its associated metadata, such as event and station information. This unified approach simplifies concurrent access, data organization, and sharing, addressing many of the limitations of previous fragmented systems. By encapsulating all essential components in a standardized manner, ASDF reduces the dependency on custom, non-reusable scripts and enhances collaboration between research groups with varied internal structures.</li>
</ol></li>
<li><p><strong>Full Provenance Support</strong>: One of the standout features of ASDF is its capability to store the complete provenance graph, capturing the history and evolution of data. This provenance tracking ensures that the origins of the data and the operations performed on it are documented, addressing issues arising from team changes, software updates, or potential processing bugs. The format thereby offers transparency and traceability, features absent or limited in other data formats.</p></li>
<li><p><strong>Synthetic Seismogram Storage</strong>: ASDF pioneers in accommodating proper storage and exchange of synthetic seismograms. This includes comprehensive documentation on the numerical solver used, earthquake parameters, the Earth model, and all factors influencing the simulation’s outcome. Given the computational intensity of generating high-frequency waveform simulations in realistic Earth models, this preservation and thorough documentation add immense value to the seismological community.</p></li>
<li><p><strong>Efficiency in File Management</strong>: ASDF offers a significant reduction in the number of files required for various tasks. A single ASDF file can effectively replace tens to hundreds of thousands of individual waveform files. This consolidation not only results in raw performance and organizational advantages but also addresses challenges like file count quota limits, especially on supercomputing platforms. Furthermore, the format supports efficient parallel I/O on suitable hardware, making it ideal for scalable parallel data processing workflows.</p></li>
<li><p><strong>Versatile Data Type Support</strong>: Beyond seismograms, ASDF is adept at accommodating diverse data types prevalent in seismology. Whether it’s spectral estimations, cross-correlations, adjoint sources, receiver functions, or other data types, ASDF ensures organized, self-describing storage. This versatility ensures that seismologists can maintain a consistent data storage paradigm across various facets of their research.</p></li>
</ol>
<p>This format is particularly suited to meet the requirements of tomorrow.</p>
<h2 id="naming-convention-and-cross-referencing">Naming Convention and Cross Referencing</h2>
<p>To enable effortless cross referecing between the different elements contained in the file adopting an consistent and standard naming convention is important.</p>
<p>This section is concerned about the cross-referencing of information related to channels allowing the waveform data, catalogue, inventory and other auxiliary data to be consistent and properly associated.</p>
<ul>
<li><strong>Trace Identifier</strong>: A unique identifier for the trace (see Obspy <a href="https://docs.obspy.org/master/packages/autogen/obspy.core.event.resourceid.ResourceIdentifier.html">documentation</a> for information on the recommended <em>resource identifier</em> structure). The trace identifier format and convention should be normalized and align with the SEED naming convention including the standard part. Deviation regarding the naming shall, howerver, be permitted to allow longer names to be utilized.<br />
</li>
<li><strong>Location Identification</strong>: The location identification convention described <a href="https://ds.iris.edu/ds/newsletter/vol1/no1/1/specification-of-seismograms-the-location-identifier/">here</a>. This convention has been adapted for μseismic monitoring in the mining context.
<ul>
<li><strong>Network Code [network_code]</strong> — Code representing the network.</li>
<li><strong>Station Code [station_code]</strong> — Code representing the station containing the digitizer.</li>
<li><strong>Location Code [location_code]</strong> — Code representing the instrument.</li>
<li><strong>Channel Code [channel_code]</strong> — The three (3) alphanumerical code representing the channel shall follow the FDSN standard naming convention of August 2000 described in the SEED document <a href="http://www.fdsn.org/pdf/SEEDManual_V2.4_Appendix-A.pdf">Appendix A</a>. For instance, a typical 14 Hz or 15 Hz omnidirectional geophone code would be GH?, where ? would be replaced by the appropriate component orientation code.</li>
</ul></li>
</ul>
<h4 id="notes">Notes:</h4>
<p><strong>Naming Convention</strong>: The full name of a component or channel is usually created as follows: <strong>channel name</strong> = <strong>network code</strong>.<strong>station code</strong>.<strong>location code</strong>.<strong>channel code</strong>.</p>
<p><strong>Network, Station, and Location Codes</strong>: The mentioned convention is often not strictly adhered to by μseismic system providers. Flexibility in applying the convention is crucial. Typically, no distinction is made between the station and location, and each instrument is assigned a unique code that may or may not refer to the data acquisition station. In such cases, we suggest using the <strong>Station Code</strong> field to store the <em>instrument</em> code and populate the location code with 01 or 00. In a network, each combination of <strong>Station Code</strong>.<strong>Location Code</strong>.<strong>Channel Code</strong> should be unique.</p>
<h4 id="suggested-naming-convention-and-usage">Suggested Naming Convention and Usage</h4>
<ul>
<li><strong>Network Code</strong>: The network code should represent a physical or logical network. A mine or mining complex can include multiple networks. The network name should be compact but be easily recognized and understood. For instance, the Oyu Tolgoi Hugo North Underground Lift 1 network can be represented by the following accronym: OTHNL1.</li>
<li><strong>Station Code</strong>: We recommend associating the station code to an instrument or a group of instrument. The Station code should convey relevant information on the sensor location and provide context to the seismic system stakeholders. An example for an adequate station code, given an instrument is installed along the Haulage Level Access Drive 2, would be HLAD2.</li>
<li><strong>Location Code</strong>: If the Station Code refers to a group of instruments, for instance, instruments installed in a long borehole, connected to the same acquisition station, the location code can be used to differentiate the instrument within the group. The location code should be kept short. It can simply be a number converying the relative order or in the case of a borehole installation, a measure of the location along the hole.</li>
</ul>
<h2 id="data-format-and-adaptation">Data Format and Adaptation</h2>
<h3 id="overview-1">Overview</h3>
<p>The key is to ensure consistencies between the data and information to allow efficient cross-referencing, retrieval and usage. The ASDF file will serve a s main container. There should be one ASDF file per event or chunk of continuous data. Grid information should not be included in the ASDF file but rather be stored in a separate file</p>
<p>In this section we will cover a series of data types some are to be included as part of the ASDF file some provided as additional files:</p>
<ul>
<li><strong>ASDF Core</strong>
<ul>
<li>[REQUIRED] <strong>Waveforms</strong></li>
<li>[REQUIRED FOR EVENT DATA, NOT INCLUDED FOR CONTINUOUS DATA] <strong>Catalog</strong></li>
<li>[REQUIRED] <strong>Inventory/System</strong></li>
</ul></li>
<li><strong>ASDF Auxiliary</strong>
<ul>
<li>[REQUIRED] <strong>System Information</strong> — important system information not included in the StationXML</li>
<li>[REQUIRED/READ ONLY] <strong>Lookup Table for Event Type Conversion</strong> — as described later in the document we suggest a mapping between the event type prescribed by the QuakeML standardard ant the event types encoutered in mining.</li>
<li>[REQUIRED] <strong>Processing Logs</strong></li>
<li>[OPTIONAL] <strong>Ray and Ray Parameters</strong> — from ray tracing</li>
<li>[OPTIONAL] <strong>Alternative Location</strong> — from Montecarlo or Jacknife analyses</li>
</ul></li>
<li><strong>Grids</strong> [NOT INCLUDED, SEPARATE FILE] — suited for velocity, velocity derivatives (e.g., slowness) attenuation and density</li>
</ul>
<p>ASDF Data Structure Overview</p>
<pre class="matematica"><code>ASDF File
|
└───Waveforms
|
└───QuakeML
|
└───StationXML
|
└───AuxiliaryData
   │
   └───SystemInfo
   |
   └───EventConversionLookup
   |
   └───
   |
   └───Ray
   |
   └───AlternativeLocations   </code></pre>
<p>We made the explicit choice to use the QuakeML and StationXML for <strong>catalog</strong> and <strong>inventory</strong> information, aligning with prevailing standards in the seismic community. The principal advantage of this decision is the assured compatibility with a multitude of existing tools and software in the seismic domain. Furthermore, both QuakeML and StationXML are inherently flexible and adaptable. These formats not only offer comprehensive sets of parameters to detail seismic events and station metadata, but they are also designed to accommodate custom parameters and extensions. This flexibility has been instrumental in our initiative. We’ve leveraged the extensibility of these formats to incorporate specialized μseismic parameters or attributes, ensuring that QuakeML and StationXML are tailored to address the unique nuances and requirements of microseismic monitoring. This adaptation ensures that the data format remains both relevant to the broader seismic community and aptly suited for microseismic applications.</p>
<p>However, like all choices, leveraging these formats comes with its challenges. While their use ensures widespread compatibility, the interpretation of file content may require nuanced processing and considerations. Some adaptations might be essential to cater specifically to the μseismic monitoring context, possibly involving the addition of auxiliary fields or annotations. The goal, throughout these modifications, remains to balance ease-of-use with the specificity required for μseismic data, ensuring that users can maximize the value derived from the data while minimizing the overhead of adaptations and interpretations.</p>
<h3 id="asdf-core">ASDF Core</h3>
<h4 id="waveform-data">Waveform Data</h4>
<p>The waveform data represents the raw vibrations recorded directly by the sensors. For convenience, waveform data can be provided in physical units native to the instrument recording the data of <span class="math inline"><em>m</em></span>, <span class="math inline"><em>m</em>/<em>s</em></span>​, or <span class="math inline"><em>m</em>/<em>s</em><sup>2</sup></span> for displacement, velocity, and acceleration, respectively. However, if size is a concern, storing the ADC counts as integers is more suitable. Storing the ADC count as integers allows for the more efficient use of compression algorithm and will allow the data to be more compact.</p>
<p>Alongside the amplitude values, additional metadata describing the instrument recording the data and time series parameters should be provided for each trace. Each trace should be stored with its own metadata information adopting the convention described in the previous section.</p>
<p>In addition to the trace identification information the following metadata must be present and accurately described the timeserie parameters</p>
<ul>
<li><strong>Sampling Rate [<code>sampling_rate</code>]</strong> — The signal’s sampling rate in samples per second.</li>
<li><strong>Calibration Factor [<code>calib</code>]</strong> — This value is optional and defaults to 1.0 if not provided. It represents the calibration factor should the sensor deviate from the typical response.</li>
<li><strong>Start Time [<code>starttime</code>]</strong> — Date and time of the first data sample given in UTC</li>
</ul>
<p>The other parameters can be derived from the sampling rate, start time and the waveform data:</p>
<ul>
<li><strong>Number of Point [<code>npts</code>]</strong> — Number of sample points. Measured by counting the number of points in the time serie.</li>
<li><strong>Sampling Interval [<code>delta</code>]</strong> — sample distance in seconds. Computed as the inverse of the sampling_rate (<code>1/sampling_rate</code>).</li>
<li><strong>End Time [<code>endtime</code>]</strong> — Date and time of the last data sample given in UTC <code>endtime = startime + npts * delta</code></li>
</ul>
<h4 id="catalog">Catalog</h4>
<p>The catalog includes information related to an event, a trigger, or a series of events. We suggest storing the catalog information in a QuakeML-like format adapted to μseismic data (see QuakeML <a href="https://quake.ethz.ch/quakeml">documentation</a>). The suggested changes affect the following QuakeML objects:</p>
<ul>
<li><strong>Event</strong> — The event_type field is restricted to specific values that are not suited for μseismic monitoring.</li>
<li><strong>Origin</strong> — The position is expressed in latitude and longitude. This will need to be changed to x, y, and z.</li>
<li><strong>Magnitude</strong> — The magnitude object would benefit from adding fields to store the corner frequency, as well as P-wave and S-wave Energy. This allows for a broad range of source parameters to be computed on the fly, rather than stored in the magnitude object. This approach is typically used in mine seismology.</li>
</ul>
<p>To ensure compatibility we suggest using the QuakeML data type as is and use a lookup table to convert QuakeML to the mining event types. The lookup table is to be stored as a dictionary as auxiliary data. The suggested mapping is described in the table below:</p>
<table>
<thead>
<tr class="header">
<th>Event Type (mining)</th>
<th>Event Type (QuakeML)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>earthquake/large event</td>
<td>earthquake</td>
</tr>
<tr class="even">
<td>seismic event</td>
<td>induced or triggered event</td>
</tr>
<tr class="odd">
<td>offsite event</td>
<td>atmospheric event</td>
</tr>
<tr class="even">
<td>rock burst</td>
<td>rock burst</td>
</tr>
<tr class="odd">
<td>fall of ground/rockfall</td>
<td>cavity collapse</td>
</tr>
<tr class="even">
<td>blast</td>
<td>explosion</td>
</tr>
<tr class="odd">
<td>blast sequence</td>
<td>accidental explosion</td>
</tr>
<tr class="even">
<td>development blast</td>
<td>industrial explosion</td>
</tr>
<tr class="odd">
<td>production blast</td>
<td>mining explosion</td>
</tr>
<tr class="even">
<td>far away blast/open pit blast</td>
<td>quarry blast</td>
</tr>
<tr class="odd">
<td>offsite blast</td>
<td>nuclear explosion</td>
</tr>
<tr class="even">
<td>paste firing</td>
<td>chemical explosion</td>
</tr>
<tr class="odd">
<td>calibration blast</td>
<td>controlled explosion</td>
</tr>
<tr class="even">
<td>other blast/slashing</td>
<td>experimental explosion</td>
</tr>
<tr class="odd">
<td>mid-shift blast/slash blast</td>
<td>industrial explosion</td>
</tr>
<tr class="even">
<td>raise bore</td>
<td>hydroacoustic event</td>
</tr>
<tr class="odd">
<td>crusher noise</td>
<td>road cut</td>
</tr>
<tr class="even">
<td>orepass noise</td>
<td>collapse</td>
</tr>
<tr class="odd">
<td>drilling noise</td>
<td>acoustic noise</td>
</tr>
<tr class="even">
<td>electrical noise</td>
<td>thunder</td>
</tr>
<tr class="odd">
<td>scaling noise</td>
<td>anthropogenic event</td>
</tr>
<tr class="even">
<td>mechanical noise</td>
<td>crash</td>
</tr>
<tr class="odd">
<td>test pulse</td>
<td>sonic boom</td>
</tr>
<tr class="even">
<td>unidentified noise/other noise</td>
<td>other event</td>
</tr>
<tr class="odd">
<td>duplicate</td>
<td>boat crash</td>
</tr>
<tr class="even">
<td>unknown</td>
<td>plane crash</td>
</tr>
<tr class="odd">
<td>tap test/test</td>
<td>avalanche</td>
</tr>
</tbody>
</table>
<p>The above mapping is implemented in the μQuake library.</p>
<h4 id="origin-coordinate-system">Origin — Coordinate System</h4>
<p>The QuakeML format was designed to store seismic data at a regional and global scale. Consequently, the QuakeML format has adopted a spherical coordinate system, storing location information in latitude and longitude.</p>
<p>Using latitude and longitude to describe mining-related events is possible but not convenient. It would require precisely knowing the series of transformations needed to convert the position expressed in the local coordinate system into longitude and latitude. We suggest overriding the latitude and longitude information and using x, y, and z instead. The use of x, y, and z notation, as opposed to the right-handed (easting, northing, and elevation) or (northing, easting, down) triplets, is to provide flexible notation and ensure consistency between the mine and the seismic system’s coordinate systems.</p>
<p>The μQuake implementation exploits the QuakeML extra parameters to store the x, y, and z values and associated errors.</p>
<h4 id="magnitude-corner-frequency-and-energy">Magnitude — Corner Frequency, and Energy</h4>
<p>The QuakeML standard does not include objects suited to store the corner frequency. The energy could be stored in the amplitude or station_magnitude object. However, this isn’t convenient, as it’s preferable for the magnitude and energy information to be used in tandem.</p>
<p>The μQuake implementation stores the <code>corner_frequency</code>, the <code>energy_p</code>, <code>energy_s</code>, and associated error alongside the magnitude information in the extra parameter of the Magnitude object.</p>
<h3 id="system-or-inventory-information">System or Inventory Information</h3>
<p>The system or inventory information is crucial for any seismic network as it provides comprehensive details about the stations and channels that are a part of that network. The StationXML format, which is an established standard in the seismic community, is designed to hold such inventory metadata.</p>
<p>However, when tailoring the use of StationXML to the μseismic domain, especially in the mining context, certain modifications are required to better fit the data’s unique characteristics and requirements.</p>
<h4 id="station-channel-coordinates">Station &amp; Channel — Coordinates</h4>
<p>In a typical seismic application, the StationXML format uses latitude and longitude to describe the geographical position of stations and channels. While this makes sense for global and regional seismic networks, it’s not as intuitive or convenient for the μseismic monitoring within a mining setup. In such a scenario, the geographical location is often best described using a local coordinate system.</p>
<p>Thus, we recommend replacing the latitude and longitude fields in the StationXML format with <code>x</code>, <code>y</code>, and <code>z</code> coordinates for both the station and channel locations. This change aligns with the earlier modifications made for QuakeML, ensuring consistency across different components of the μseismic system.</p>
<h2 id="rfc-section-system-information-storage-in-asdfs-auxiliary-data">RFC Section: System Information Storage in ASDF’s Auxiliary Data</h2>
<h3 id="background">Background</h3>
<p>To ensure accurate interpretation and utilization of seismic data, it’s essential to provide comprehensive system information. This information offers the necessary context about the recording environment, location, and equipment specifics, which can be pivotal in analysis phases.</p>
<h3 id="proposed-data-structure">Proposed Data Structure</h3>
<h4 id="directory-structure">Directory Structure:</h4>
<ul>
<li>Within the <code>AuxiliaryData</code> section of the ASDF file, we introduce a dedicated <code>SystemInfo</code> directory.</li>
<li>This directory will consolidate all relevant information about the seismic system setup.</li>
</ul>
<h4 id="system-attributes">System Attributes:</h4>
<p>The <code>SystemInfo</code> directory will house the following attributes:</p>
<ul>
<li><code>country</code>: The nation where the system is located.</li>
<li><code>time_zone</code>: Local time zone of the system or the offset from Coordinated Universal Time (UTC). The time zone name must be found with the <a href="https://www.iana.org/time-zones">IANA time zone database</a></li>
<li><code>site_name</code>: Name or identifier of the seismic site.</li>
<li><code>latitude</code>: Geographic latitude of the system’s location.</li>
<li><code>longitude</code>: Geographic longitude of the system’s location.</li>
<li><code>depth</code>: Altitude of the system.</li>
<li><code>installation_date</code>: Date when the system was set up.</li>
<li><code>removal_date</code>: Date when the system was removed (if applicable).</li>
<li><code>monitoring_target</code>: The monitoring target (e.g. underground, open-pit, surface)</li>
<li><code>Description</code>: Additional remarks or details about the site or instrumentation.</li>
</ul>
<h3 id="implementation-notes">Implementation Notes:</h3>
<h3 id="data-structure-inside-asdf-for-systeminfo">Data Structure Inside ASDF for SystemInfo</h3>
<p>Inside <code>SystemInfo</code>, each attribute (like <code>country</code>, <code>time_zone</code>, <code>latitude</code>, etc.) are a dataset. Datasets in HDF5 (and thus ASDF) are essentially multidimensional arrays of data elements, accompanied by metadata. For many of our attributes, these datasets would just be single values (like a single string for <code>country</code>), but the structure allows for more complex data if needed.</p>
<p>For example:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode mathematica"><code class="sourceCode mathematica"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true"></a>`AuxiliaryData</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true"></a>│</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true"></a>└───SystemInfo</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true"></a>    │   Country = &quot;USA&quot;</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true"></a>    │   <span class="dt">time_</span>zone = &quot;PST&quot;</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true"></a>    │   <span class="fu">latitude</span> = <span class="dv">34</span><span class="fl">.0522</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true"></a>    │   <span class="fu">longitude</span> = <span class="dv">-118</span><span class="fl">.2437</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true"></a>    │   ...` </span></code></pre></div>
<h3 id="code-examples">Code Examples</h3>
<p>To interact with ASDF, we can use Python with the <code>pyasdf</code> library. Here’s a hypothetical code snippet to add <code>SystemInfo</code> to an ASDF file:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true"></a><span class="im">import</span> pyasdf</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true"></a></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true"></a><span class="co"># Load an existing ASDF dataset or create a new one</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true"></a><span class="cf">with</span> pyasdf.ASDFDataSet(<span class="st">&quot;path_to_asdf_file.h5&quot;</span>, mode<span class="op">=</span><span class="st">&quot;a&quot;</span>) <span class="im">as</span> ds:</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true"></a></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true"></a>    <span class="co"># Create a new auxiliary data group for SystemInfo</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true"></a>    system_info <span class="op">=</span> ds.create_auxiliary_data_group(<span class="st">&quot;SystemInfo&quot;</span>)</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true"></a></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true"></a>    <span class="co"># Add data to this group</span></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true"></a>    system_info.create_dataset(name<span class="op">=</span><span class="st">&quot;country&quot;</span>, data<span class="op">=</span><span class="st">&quot;USA&quot;</span>)</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true"></a>    system_info.create_dataset(name<span class="op">=</span><span class="st">&quot;time_zone&quot;</span>, data<span class="op">=</span><span class="st">&quot;PST&quot;</span>)</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true"></a>    system_info.create_dataset(name<span class="op">=</span><span class="st">&quot;latitude&quot;</span>, data<span class="op">=</span><span class="fl">34.0522</span>)</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true"></a>    system_info.create_dataset(name<span class="op">=</span><span class="st">&quot;longitude&quot;</span>, data<span class="op">=-</span><span class="fl">118.2437</span>)</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true"></a>    <span class="co"># ... similarly for other attributes</span></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true"></a></span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true"></a><span class="co"># Check the data</span></span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true"></a><span class="cf">with</span> pyasdf.ASDFDataSet(<span class="st">&quot;path_to_asdf_file.asdf&quot;</span>) <span class="im">as</span> ds:</span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true"></a>    <span class="bu">print</span>(ds.auxiliary_data.SystemInfo.Country[:])  <span class="co"># Should print &#39;USA&#39;` </span></span></code></pre></div>
<p>For reading the <code>SystemInfo</code>:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true"></a><span class="im">import</span> pyasdf</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true"></a></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true"></a><span class="cf">with</span> pyasdf.ASDFDataSet(<span class="st">&quot;path_to_asdf_file.asdf&quot;</span>) <span class="im">as</span> ds:</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true"></a>    country <span class="op">=</span> ds.auxiliary_data.SystemInfo.country[:]</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true"></a>    timezone <span class="op">=</span> ds.auxiliary_data.SystemInfo.TimeZone[:]</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true"></a>    latitude <span class="op">=</span> ds.auxiliary_data.SystemInfo.Latitude[:]</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true"></a>    longitude <span class="op">=</span> ds.auxiliary_data.SystemInfo.Longitude[:]</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true"></a>    <span class="co"># ... and so on` </span></span></code></pre></div>
<p>It’s important to note that this example assumes the <code>pyasdf</code> library has (or will have) methods named as described. In practice, depending on the actual <code>pyasdf</code> version and methods available, there may be variations in how you interact with the file. Always refer to the documentation of the library for accurate and up-to-date information.</p>
<h3 id="system-metadata-and-grid-data">System Metadata and Grid Data</h3>
<p>To fully enable the interpretation of the seismic data, accessing information on the velocity models is essential. Other important although not as essential are the attenuation model if they exist and the density values or model. The velocity values/models are increasingly represented on a grid.</p>
<p>In this section, we propose using a simple grid format for data exchange.</p>
<h4 id="grid-format-overview">Grid Format Overview</h4>
<p>The grid format is structured to represent the velocity model in a systematic, gridded layout. It comprises two main components: the header, which contains metadata about the grid, and the grid values that reflect the actual data.</p>
<h5 id="header">Header</h5>
<p>The header is a crucial section that offers insights into the grid’s specifications, such as its dimensions, the starting point (origin) of the grid, and the intervals or spacings between grid points. A sample header in Python dictionary format might look like:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true"></a>header <span class="op">=</span> {</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true"></a>    <span class="st">&quot;NX&quot;</span>: <span class="dv">100</span>,            <span class="co"># Number of grid points in the X direction</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true"></a>    <span class="st">&quot;NY&quot;</span>: <span class="dv">100</span>,            <span class="co"># Number of grid points in the Y direction</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true"></a>    <span class="st">&quot;NZ&quot;</span>: <span class="dv">50</span>,             <span class="co"># Number of grid points in the Z direction</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true"></a>    <span class="st">&quot;ORIGX&quot;</span>: <span class="fl">0.0</span>,         <span class="co"># X coordinate of the grid origin</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true"></a>    <span class="st">&quot;ORIGY&quot;</span>: <span class="fl">0.0</span>,         <span class="co"># Y coordinate of the grid origin</span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true"></a>    <span class="st">&quot;ORIGZ&quot;</span>: <span class="fl">0.0</span>,         <span class="co"># Z coordinate of the grid origin</span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true"></a>    <span class="st">&quot;SPACEX&quot;</span>: <span class="fl">0.1</span>,        <span class="co"># Grid spacing in the X direction</span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true"></a>    <span class="st">&quot;SPACEY&quot;</span>: <span class="fl">0.1</span>,        <span class="co"># Grid spacing in the Y direction</span></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true"></a>    <span class="st">&quot;SPACEZ&quot;</span>: <span class="fl">0.2</span>,        <span class="co"># Grid spacing in the Z direction</span></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true"></a>}</span></code></pre></div>
<p>This dictionary effectively captures the grid’s spatial boundaries, intervals, and the type of data contained.</p>
<h5 id="grid-data">Grid Data</h5>
<p>The grid data values follow the header. Organized in a sequence, they represent their positions within the grid. For simplicity and efficiency, these values can be represented as a 2D numpy array:</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true"></a></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true"></a><span class="co"># For demonstration purposes, initializing a 2D array with NXxNYxNZ dimensions</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true"></a>grid_values <span class="op">=</span> np.zeros((header[<span class="st">&quot;NX&quot;</span>], header[<span class="st">&quot;NY&quot;</span>], header[<span class="st">&quot;NZ&quot;</span>]))</span></code></pre></div>
<p>In this representation, the grid values are stored in a structured manner, allowing for easy indexing and operations. Each cell in the array corresponds to a grid point in the velocity model, with its value representing the velocity (or density or attenuation, depending on the grid type) at that point.</p>
<h3 id="data-format-for-storing-ray-information-in-asdf">Data Format for Storing Ray Information in ASDF</h3>
<h4 id="background-1">Background</h4>
<p>For efficient microseismic monitoring and analysis, the inclusion of ray tracing data alongside waveform and inventory data is beneficial. In keeping with the extensibility and flexibility features of the ASDF format, we propose a systematic structure to store the ray information.</p>
<h4 id="proposed-data-structure-1">Proposed Data Structure</h4>
<h5 id="directory-structure-1">Directory Structure:</h5>
<ul>
<li>Within the <code>AuxiliaryData</code> section of the ASDF file, we introduce a dedicated <code>Rays</code> directory.</li>
<li>Individual rays are uniquely identified by a unique <code>resource_id</code> and each has its own sub-directory under <code>Rays</code> and adopt a naming convention linking them to the an instrument using the <code>network</code>, <code>station</code> and <code>channel</code> codes.</li>
</ul>
<h5 id="ray-attributes">Ray Attributes:</h5>
<p>Each ray’s sub-directory will include the following attributes:</p>
<ul>
<li><code>network_code</code>: Identifier for the network. Standard naming conventions of seismic networks are to be employed.</li>
<li><code>station_code</code>: Identifier for the station. This aligns with the standard naming conventions employed for seismic stations.</li>
<li><code>location_code</code>: A code that uniquely identifies different data streams at a single station. It allows users to distinguish between data from closely spaced instruments or multiple data collection strategies.</li>
<li><code>arrival_id</code>: The unique <code>ResourceIdentifier</code> of the associated seismic arrival included in the QuakeML section of the ASDF file.</li>
<li><code>phase</code>: The seismic phase (“P” or “S”).</li>
<li><code>azimuth</code>: Azimuth in degrees.</li>
<li><code>takeoff_angle</code>: Takeoff angle in degrees.</li>
<li><code>travel_time</code>: Travel time between the seismic source and the recording site in seconds.</li>
<li><code>earth_model_id</code>: A <code>ResourceIdentifier</code> representing the velocity model used.</li>
<li><code>length</code>: Computed length of the ray representing the distance along the raypath between an event and a sensor</li>
<li><code>baz</code>: Computed back azimuth of the ray.</li>
<li><code>incidence_angle</code>: Computed incidence angle of the ray.</li>
</ul>
<h5 id="ray-datasets">Ray Datasets:</h5>
<ul>
<li>A dataset named <code>nodes</code> in each ray’s sub-directory, storing the array of nodes that describe the ray path.</li>
</ul>
<h4 id="implementation-notes-1">Implementation Notes:</h4>
<ol type="1">
<li><p><strong>Creating Rays in ASDF</strong>:</p>
<ul>
<li>Users are encouraged to use existing ASDF software tools to initiate and modify the ASDF file structure.</li>
<li>During ray storage, a serialization function or method will be required to transform the <code>Ray</code> object into the above-proposed ASDF-compatible structure.</li>
</ul></li>
<li><p><strong>Retrieving Rays from ASDF</strong>:</p>
<ul>
<li>A corresponding deserialization function or method will be essential to read rays from the ASDF format, converting them back into <code>Ray</code> objects.</li>
</ul></li>
<li><p><strong>Compatibility and Integration</strong>:</p>
<ul>
<li>The proposed structure ensures seamless integration with waveform and inventory data. The use of <code>network_code</code>, <code>station_code</code>, and <code>location_code</code> ensures that rays can be directly associated with specific waveform data and inventory components.</li>
</ul></li>
</ol>
<h4 id="point-cloud-data">Point Cloud Data</h4>
<h4 id="lookup-table-for-event-type-conversion">Lookup Table for Event Type Conversion</h4>
<h2 id="implementation-using-the-μquake-python-library">Implementation using the μQuake Python Library</h2>
<p>Within the context of this RFC, which proposes specific adaptations and formats tailored to microseismic monitoring, the <code>uquake</code> library stands as a practical implementation of these recommendations. Developed in Python and built upon ObsPy, <code>uquake</code> has been specially crafted to cater to the distinctive needs of microseismic monitoring in mining environments. This includes, amongst other capabilities, the handling of local coordinate systems and unique event types frequently observed in mine microseismic monitoring. For those seeking an immediate and tangible application of the proposed data format recommendations from this RFC, <code>uquake</code> offers a ready solution. It is open source, distributed under AGPL license and publicly available and can be easily accessed and installed via pip using <code>pip install uquake</code>.</p>
<p>Note that there are alternative libraries addressing the same issues μQuake tackles. The author is, howerver, less familiar with the alternatives. Notable alternatives are</p>
<p>The Niosh <a href="https://github.com/niosh-mining/obsplus">Obsplus</a> <a href="https://github.com/DASDAE/dascore">DASCORE</a></p>
<h3 id="implementation-using-uquake">Implementation using <code>uquake</code></h3>
<p>The <code>uquake</code> library provides the necessary tools to handle gridded data in seismology. One of the primary objects to manage such grid data is the <code>Grid</code> class from <code>uquake.core.grid.base</code>. This class is designed to hold regular grids and can be employed for both 2D and 3D data structures.</p>
<h4 id="initializing-a-grid">Initializing a Grid</h4>
<p>The <code>Grid</code> object can be initialized using either a numpy array representing the grid data or by specifying the grid dimensions. When using the latter approach, the grid is initialized with a default or specified value.</p>
<p>Let’s consider a simple example to illustrate this:</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true"></a><span class="im">from</span> uquake.core.grid.base <span class="im">import</span> Grid</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true"></a></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true"></a><span class="co"># Define grid header specifications</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true"></a></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true"></a>header <span class="op">=</span> {</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true"></a>    <span class="st">&quot;NX&quot;</span>: <span class="dv">100</span>,  </span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true"></a>    <span class="st">&quot;NY&quot;</span>: <span class="dv">100</span>,  </span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true"></a>    <span class="st">&quot;NZ&quot;</span>: <span class="dv">50</span>,   </span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true"></a>    <span class="st">&quot;ORIGX&quot;</span>: <span class="fl">0.0</span>,  </span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true"></a>    <span class="st">&quot;ORIGY&quot;</span>: <span class="fl">0.0</span>,  </span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true"></a>    <span class="st">&quot;ORIGZ&quot;</span>: <span class="fl">0.0</span>,  </span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true"></a>    <span class="st">&quot;SPACEX&quot;</span>: <span class="fl">0.1</span>,  </span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true"></a>    <span class="st">&quot;SPACEY&quot;</span>: <span class="fl">0.1</span>,  </span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true"></a>    <span class="st">&quot;SPACEZ&quot;</span>: <span class="fl">0.2</span>,  </span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true"></a>}</span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true"></a></span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true"></a><span class="co"># Initialize the grid using grid dimensions and set default value as 0</span></span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true"></a></span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true"></a>grid_dims <span class="op">=</span> (header[<span class="st">&quot;NX&quot;</span>], header[<span class="st">&quot;NY&quot;</span>], header[<span class="st">&quot;NZ&quot;</span>])</span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true"></a>spacing <span class="op">=</span> (header[<span class="st">&quot;SPACEX&quot;</span>], header[<span class="st">&quot;SPACEY&quot;</span>], header[<span class="st">&quot;SPACEZ&quot;</span>])</span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true"></a>origin <span class="op">=</span> (header[<span class="st">&quot;ORIGX&quot;</span>], header[<span class="st">&quot;ORIGY&quot;</span>], header[<span class="st">&quot;ORIGZ&quot;</span>])</span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true"></a></span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true"></a>grid <span class="op">=</span> Grid(data_or_dims<span class="op">=</span>grid_dims, spacing<span class="op">=</span>spacing, origin<span class="op">=</span>origin, value<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true"></a></span>
<span id="cb7-26"><a href="#cb7-26" aria-hidden="true"></a><span class="co"># Write the modified or new grid to a file</span></span>
<span id="cb7-27"><a href="#cb7-27" aria-hidden="true"></a>grid.write(<span class="st">&quot;path_to_new_grid_file.grid&quot;</span>)</span></code></pre></div>
<p>Here, we’ve initialized a 3D grid using the dimensions specified in the header. The grid is filled with a default value of 0.</p>
<h4 id="reading-and-writing-grids">Reading and Writing Grids</h4>
<p>The <code>Grid</code> object is equipped with methods to read and write grid data, making it easy to load existing grids or store newly created or modified grids.</p>
<p>Here’s an example of how one might read from and write to a grid file:</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true"></a><span class="co"># all versions</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true"></a><span class="im">from</span> uquake.core.grid <span class="im">import</span> read_grid</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true"></a></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true"></a><span class="co"># Reading a grid from a file</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true"></a>grid_from_file <span class="op">=</span> Grid.read(<span class="st">&quot;path_to_grid_file.grid&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb9"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true"></a><span class="co"># from version 2.0.1</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true"></a><span class="co"># Reading a grid from a file</span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true"></a>grid_from_file <span class="op">=</span> Grid.read(<span class="st">&quot;path_to_grid_file.grid&quot;</span>) </span></code></pre></div>
<p>This approach simplifies the process of handling gridded data in seismology by using the <code>uquake</code> library’s built-in functionalities.</p>
<h2 id="rationale-1">Rationale</h2>
<p>Understanding the motivations and reasons behind any proposed change is essential to ensure clarity, gain stakeholder buy-in, and ensure the technical merits of the proposal align with the broader goals.</p>
<ol type="1">
<li><p><strong>Choice of Data Packaging Formats</strong>: The decision to employ ASDF for the encapsulation of both catalog information and waveform data, combined with the inherent XML structure for QuakeML, is rooted in their respective proficiencies and widespread acceptance within the industry. ASDF provides an efficient mechanism for storing and fetching data, especially when dealing with substantial datasets. Concurrently, the integral XML structure guarantees interoperability with systems customarily developed for QuakeML processing.</p></li>
<li><p><strong>Adapting QuakeML for μseismic Data</strong>: Traditional QuakeML formats, while robust for standard seismology needs, are not fully suited to address the nuances of μseismic data. The unique requirements of μseismic monitoring, especially in mining contexts, necessitate modifications to the existing format. By making these adjustments, the system becomes more flexible and directly applicable to the μseismic domain, allowing for better data representation and interpretation.</p></li>
<li><p><strong>Use of a Grid for Velocity Models</strong>: Seismic data interpretation largely hinges on the accuracy and clarity of velocity models. The industry trend has shifted towards grid representations of these models due to their higher precision and ease of use. Implementing a standard grid format for data exchange promotes interoperability and standardization across systems and tools.</p></li>
<li><p><strong>Introduction of the <code>uquake</code> Library</strong>: The seismic domain has various software libraries that cater to specific needs. The choice of <code>uquake</code> was driven by its capabilities to manage the proposed data structures efficiently and its extensibility to cater to future modifications. By embedding support for the newly proposed data structures directly within <code>uquake</code>, users can expect a seamless experience and avoid the complexities associated with multi-tool workflows.</p></li>
<li><p><strong>Latitude and Longitude to X, Y, Z Conversion</strong>: Given that most mining operations work on local coordinate systems rather than global ones, expressing positions in terms of x, y, and z becomes not just convenient, but also essential. This shift eliminates the need for complex transformations and ensures data is immediately useful for local operations and analysis.</p></li>
</ol>
<p>In summary, the proposed changes and implementations in this RFC stem from a direct need to address the unique challenges posed by μseismic monitoring, especially in mining contexts. They reflect both the evolution of seismic data interpretation methodologies and the tools used in the industry. Through these proposals, we aim to establish a more streamlined, precise, and standardized approach to μseismic data management and interpretation.</p>
<h3 id="feedback-mechanism">Feedback Mechanism</h3>
<p>Feedback and contributions from the community are essential to refining and improving this RFC. There are two primary ways through which stakeholders, developers, and interested parties can provide their feedback:</p>
<ol type="1">
<li><p><strong>GitHub Issues</strong>:</p>
<ul>
<li>Navigate to the <a href="https://github.com/Microquake-ai/RFC-micro-seismic-data-exchange-format/tree/main">RFC micro-seismic data exchange format repository on GitHub</a>.</li>
<li>Go to the <code>Issues</code> tab.</li>
<li>Click on <code>New Issue</code> to create a new issue.</li>
<li>Provide a concise title and detailed description of your feedback, suggestions, or concerns.</li>
<li>Once submitted, the issue will be visible to the community, and the project maintainers will review and address it as appropriate.</li>
</ul></li>
<li><p><strong>Email</strong>:</p>
<ul>
<li>If you prefer a more direct approach or have feedback that you’d like to keep private, you can send an email to <a href="mailto:rfc_format@microquake.ai">rfc_format@microquake.ai</a>.</li>
<li>Please provide a clear subject line relevant to your feedback to ensure swift handling of your email.</li>
<li>While we appreciate all feedback, do note that due to the volume of emails, it might take some time before you receive a response.</li>
</ul></li>
</ol>
<p>Whether you choose to leave an issue on GitHub or send an email, your feedback is invaluable. It aids in ensuring that the proposed micro-seismic data exchange format is robust, relevant, and addresses the needs of the community.</p>
<p>Thank you for taking the time to review this RFC and for your contributions towards its continual improvement.</p>
<h2 id="references">References</h2>
<p>Krischer, L., Smith, J. A., Lei, W., Lefebvre, M., Ruan, Y., &amp; Tromp, J. (2016). An Adaptable Seismic Data Format. Geophysical Journal International, 207(2), 1003–1011. <a href="https://academic.oup.com/gji/article/207/2/1003/2583765">Link</a></p>
<!--stackedit_data:
eyJoaXN0b3J5IjpbOTg3ODE2NDI5LDEzOTQ0Njk2NjYsMTA3ND
AwOTM3OCwyMDIzMjQ5MTg4LC0xMjM1MDIyNzkzLC02NTcxNjk0
NzYsLTE0NTA3NzY3NDMsNzU2NTkxOTA5LDYyMTYxNjQwMSwxOD
EwNjY4NTM2LDcxOTYzMzA5NSwxMzM5MzUwMTMsLTIxNDU0ODU0
MjEsLTE4NzM2NDI4MjQsLTgwMzQxNzQ4NCwtMTEyNDU5OTkzOS
wxNDI5MTkyOTI2LDI5MTY4OTEzNiwxOTk0NDk1NjMyLC02NDIy
MTgxMjNdfQ==
-->
