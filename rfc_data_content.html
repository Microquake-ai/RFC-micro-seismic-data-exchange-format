<h1 id="request-for-comment-content-for-μseismic-data-exchange">Request For Comment — Content for μSeismic Data Exchange</h1>
<h2 id="introduction">Introduction</h2>
<h3 id="purpose">Purpose</h3>
<p>The purpose of this document is to invite comments on a suggested format to allow for standardized and consistent access to μseismic data collected by mine μseismic monitoring systems. This format aims to enable a seamless and lossless exchange between different platforms. The objective of the proposed standard <strong>does not</strong> concern how seismic data are <strong>internally managed</strong> within each proprietary platform, although the capability of the present format would be suited for that purpose, it only focuses on how the data are exchanged.</p>
<p>The proposed standard applies to a wide range of data including triggered event, continuous recording, and DAS monitoring. It allows for different data types to be combined.</p>
<p>Access to the μseismic data is inconsistent among various vendors, and occasionally within different implementations by the same vendor. Variations arise from site to site, often driven by third-party requirements. Such inconsistencies lead to inefficiencies, complicating the integration of various systems that offer complementary products and services, and making data usage unnecessarily challenging.</p>
<p>In light of recent advancements in μseismic monitoring technology, the imperative for a standardized format becomes even more salient. The microseismic monitoring landscape is evolving, marked by the deployment of increasingly expansive monitoring systems. These systems, given their extensive scale, inherently produce voluminous data sets. Furthermore, the incursion of Distributed Acoustic Sensing (DAS) in mining adds another layer of complexity, both in terms of data volume and diversity. DAS, with its high spatial resolution and continuous monitoring capability, generates data at an unprecedented scale. A robust and standardized format is crucial to efficiently manage, process, and interpret these burgeoning data streams, ensuring that the rich information they provide can be harnessed effectively and cohesively.</p>
<p>This document proposes a file structure and format. At this stage, we seek alignment on the content of the information transferred and consensus on the container format.</p>
<h3 id="scope">Scope</h3>
<p>With the increasing volume of μseismic data collected, especially in modern expansive monitoring systems and with technologies like Distributed Acoustic Sensing (DAS), there is a need for efficient management and handling of this data. The scope of this proposed standard is to define the content and nature of μseismic information provided to third parties and to suggest a format that facilitates efficient storage, retrieval, and exchange, of complete information required to further analyse the data.</p>
<p>Computational efficiency in storing and retrieving large volume of data that are prescribed by increasingly expansive system and the adoption of the DAS technology, is central. The ability to provide a storage mechanism flexible and extensible enough to package both triggered and continous data is another objective.</p>
<p>The standard focuses on the foundational elements and seismic information intrinsic to μseismic monitoring including:</p>
<ul>
<li><strong>Waveforms</strong> — This includes the raw, unprocessed waveform for both continuous and triggered data.</li>
<li><strong>Catalog Information</strong> — This covers event information derived from waveform data processing.</li>
<li><strong>Inventory or System Information</strong> — Details about the instruments (sensors and data acquisition modules) used in the data acquisition chain are included here, along with other critical data processing information, such as velocity, density, and attenuation values or models.</li>
</ul>
<h3 id="rationale">Rationale</h3>
<h4 id="need-for-a-new-standard">Need for a New Standard</h4>
<p>The increase in microseismic data, particularly from expansive monitoring systems and new technologies like Distributed Acoustic Sensing (DAS), underscores the pressing need for a more efficient and unified data format. Currently, the varied nature of microseismic data formats hinders streamlined integration and analysis, posing challenges in managing and deriving value dataset collected by in-mine monitoring system. The lossy and incoherent nature of current data exchange formats are hindering innovation and make the utilization of μseismic data unecessarily difficul. Given the critical importance of microseismic data in ensuring the safety and improving the operations of underground mining, establishing a standardized format and mechanism of echange becomes imperative. The propose standard objective is to facilitate more straightforward data access, efficient storage, and smoother data exchanges across different platforms for a variety of data types.</p>
<h4 id="goal">Goal</h4>
<p>The primary objective of this RFC is to introduce a proposed data content, packaging format, and naming conventions that are aimed at enhancing interoperability, consistency, and innovation within the sphere of microseismic monitoring. As we acknowledge the integral role of microseismic data in underground mining operations’ safety and efficiency, this proposal serves as a step forward in harmonizing and optimizing the way in which data is accessed, managed, and exchanged across diverse platforms in the industry.</p>
<p>To this end, this proposal seeks to:</p>
<ul>
<li><p><strong>Promote Universality</strong>: By implementing a unified format tailored specifically for microseismic monitoring systems, the intent is to transcend vendor-specific or third-party constraints, allowing seamless integration across a range of platforms.</p></li>
<li><p><strong>Ensure Scalability</strong>: Given the rising volume of data being generated by expansive microseismic monitoring systems, particularly with the advent of Distributed Acoustic Sensing (DAS) technology, the proposed format is designed to accommodate large datasets without compromising on efficiency or speed of data retrieval.</p></li>
<li><p><strong>Enhance Clarity and Coherence</strong>: Implementing a standardized naming convention ensures a structured approach to data management, reducing ambiguities and promoting swift, clear data identification and processing.</p></li>
<li><p><strong>Facilitate Innovation</strong>: With a consistent, standardized foundation in place, researchers, developers, and industry professionals will be better poised to innovate, iterate, and develop new tools, methodologies, and solutions that harness the full potential of microseismic data.</p></li>
</ul>
<p>In summary, the goal is to provide a robust framework that not only addresses the present challenges posed by varied data formats but also anticipates and caters to the evolving needs of the microseismic monitoring industry. Through this proposed standard, we endeavor to usher in an era of streamlined data access, management, and exchange that can truly capitalize on the advancements in microseismic monitoring technology.</p>
<h3 id="rfc-process-and-schedule">RFC Process and Schedule</h3>
<p>We propose the following RFC process that should lead to the standard adoption. It is unclear at this time where and by who the standard will be published.</p>
<h4 id="process">Process:</h4>
<ol type="1">
<li><strong>Drafting</strong>: Development of the initial RFC document.</li>
<li><strong>Publication</strong>: Making the RFC available for a wider audience for review and comment.</li>
<li><strong>Review</strong>: A period of review where stakeholders provide feedback.</li>
<li><strong>Revision</strong>: Updates to the RFC based on feedback received.</li>
<li><strong>Final Comment Period</strong>: A last opportunity for feedback before a the final standard is published.</li>
<li><strong>Adoption</strong>: Adoption of the RFC.</li>
<li><strong>Publication</strong>: If adopted, the Standard is officially published.</li>
<li><strong>Implementation</strong>: Introduction of the recommended practices or standards from the RFC.</li>
<li><strong>Review Cycle</strong>: Periodic reviews of the RFC’s effectiveness post-implementation.</li>
</ol>
<h4 id="schedule">Schedule:</h4>
<ul>
<li><ol type="1">
<li><strong>Drafting and Initial Publication</strong>: Completed as of 2023-10-20.</li>
</ol></li>
</ul>
<ol start="2" type="1">
<li><strong>Review</strong>: Given the complexities and the necessity to involve various stakeholders, we suggest allocating four months to the review. This will ensure that all participants have ample time to understand, discuss, and provide thoughtful feedback.
<ul>
<li><strong>Start</strong>: 2023-11</li>
<li><strong>End</strong>: 2023-03</li>
</ul></li>
<li><strong>Revision</strong>: Considering the extended review period and potential for substantial feedback, one months will be set aside for revisions.
<ul>
<li><strong>Start</strong>: 2023-03</li>
<li><strong>End</strong>: 2023-04</li>
</ul></li>
<li><strong>Final Comment Period</strong>: This phase allows stakeholders another chance to review the revised RFC and provide final comments. Two months seems reasonable for this step, given the extended timeline for other phases.
<ul>
<li><strong>Start</strong>: 2023-04</li>
<li><strong>End</strong>: 2023-06</li>
</ul></li>
<li><strong>Adoption</strong>: The adoption mechanism has to be determined. There is currently no body governing microseismic monitoring.
<ul>
<li><strong>Date</strong>: 2023-06</li>
</ul></li>
<li><strong>Official Publication</strong>: After finalizing the adoption, a week is allocated for any final edits, formatting, and dissemination of the standard.
<ul>
<li><strong>Date</strong>: 2023-07</li>
</ul></li>
<li><strong>Implementation and Review Cycle</strong>: As before, this is a longer-term step and its start would be dependent on the decisions made and the complexity of the implementation.
<ul>
<li><strong>Start</strong>: 2023-07</li>
<li><strong>Review Cycle</strong>: Every 6 months (or another interval that makes sense based on the nature of the standard and its implications)</li>
</ul></li>
</ol>
<h2 id="proposal">Proposal</h2>
<h3 id="overview">Overview</h3>
<p>Our proposal encompasses three categories of data: the waveforms, the catalog data, and the inventory and system information. It also concerns system metadata such as velocity models.</p>
<p>We propose using the <code>ASDF</code> format with a <code>.asdf</code> extension to store the waveforms, the catalog (QuakeML), and inventory (StationXML) information. The <code>ADSF</code> format provides a convenient and comprehensive mechanism to store the provenance and lineage information related to the data genesis and modification to provide traceability and data history. Note that the <code>ASDF</code> format also provides a convenient way to store auxiliary data that could, for instance, include including but not necessarily limited to:</p>
<ul>
<li><p><strong>Ambient Noise Correlations</strong>: Pre-computed cross-correlations between stations, which can be essential for techniques like ambient noise tomography.</p></li>
<li><p><strong>Instrument Response</strong>: Though typically part of the StationXML, having the actual instrument response curves stored as auxiliary data can facilitate more direct correction of the waveforms without referencing external databases.</p></li>
<li><p><strong>Ray Tracing and Ray Parameters</strong>:</p></li>
<li><p><strong>Processing Logs</strong>: Detailed logs of processing steps performed on the data, which can be crucial for ensuring data quality and understanding potential issues or artifacts.</p></li>
</ul>
<p>To ensure interoperability, the information in the provided files must be consistent. The sensor naming convention shall remain consistent throughout. Additionally, the locations of sensors and events should be expressed using a unified coordinate system, which must also be used for grids, if applicable.</p>
<h3 id="why-asdf-format">Why <code>ASDF</code> format?</h3>
<p>The Adaptable Seismic Data Format (ASDF) was introduced in response to the need for an efficient and comprehensive format for seismic data storage and retrieval. Developed through collaborative research by experts in the seismology field, ASDF aims to address the complexities associated with managing diverse seismic datasets. The format has been designed with adaptability in mind, ensuring both ease of use and interoperability across various platforms. As a result of its well-structured architecture, ASDF has gained widespread acceptance within the seismology community.</p>
<p>The <code>ASDF</code> format was designed to efficiently store and access large-scale array-oriented scientific data. Its design addresses the challenges posed by cloud and distributed storage, allowing for concurrent reads and writes. The format shines in scenarios where data needs to be analyzed in chunks without loading the entire dataset into memory, making it particularly apt for multidimensional arrays. With built-in support for compression and chunking, ASDF facilitates rapid data access regardless of the storage backend, whether it’s file systems, object storage, or databases.</p>
<p>The ASDF (Adaptable Seismic Data Format) file structure is meticulously designed to cater to the specific needs of modern seismology. Central to its architecture is the seamless integration of seismic waveforms and associated metadata, ensuring the cohesiveness of data and information. The format organizes its content into two principal components: (1) the seismic waveforms, stored as time series data, and (2) the metadata, which incorporates station and event information using standardized formats such as StationXML and QuakeML. This harmonization ensures uniformity in the representation of seismic stations and earthquake event details. Processing histories, provenance details, as well as auxiliary data like adjoint sources and receiver functions, can also be embedded, further enhancing the format’s comprehensive nature. A distinguishing trait of ASDF is its optimization for parallel I/O operations, positioning it as a prime choice for high-performance computing environments. The principles, design considerations, and virtues of the ASDF architecture have been expansively documented in the Geophysical Journal International (Krischer et al., 2016) <a href="https://chat.openai.com/c/78d37cb0-1768-4534-8a30-dad9fe3d2f0c#user-content-fn-1%5E">1</a>.</p>
<p>By adopting <code>ASDF</code>, we can store data and metadata in formats closely aligned with those widely accepted by the seismology community. It’s feasible to encapsulate waveforms, event catalogs, and system information within a single container, enabling standalone usage. Additionally, the format can be tailored to accommodate variations in the information required for triggered and continuous data.</p>
<p>The benefits of using the <code>ASDF</code> format become particularly evident when considering the nature of waveform data. More broadly, the main benefit of employing the <code>ASDF</code> format to store seismic data and metadata include:</p>
<ol type="1">
<li><ol type="1">
<li><strong>Integrated Storage and Organization</strong>: ASDF is a comprehensive and well-defined format that seamlessly integrates seismological waveform data and its associated metadata, such as event and station information. This unified approach simplifies concurrent access, data organization, and sharing, addressing many of the limitations of previous fragmented systems. By encapsulating all essential components in a standardized manner, ASDF reduces the dependency on custom, non-reusable scripts and enhances collaboration between research groups with varied internal structures.</li>
</ol></li>
<li><p><strong>Full Provenance Support</strong>: One of the standout features of ASDF is its capability to store the complete provenance graph, capturing the history and evolution of data. This provenance tracking ensures that the origins of the data and the operations performed on it are documented, addressing issues arising from team changes, software updates, or potential processing bugs. The format thereby offers transparency and traceability, features absent or limited in other data formats.</p></li>
<li><p><strong>Synthetic Seismogram Storage</strong>: ASDF pioneers in accommodating proper storage and exchange of synthetic seismograms. This includes comprehensive documentation on the numerical solver used, earthquake parameters, the Earth model, and all factors influencing the simulation’s outcome. Given the computational intensity of generating high-frequency waveform simulations in realistic Earth models, this preservation and thorough documentation add immense value to the seismological community.</p></li>
<li><p><strong>Efficiency in File Management</strong>: ASDF offers a significant reduction in the number of files required for various tasks. A single ASDF file can effectively replace tens to hundreds of thousands of individual waveform files. This consolidation not only results in raw performance and organizational advantages but also addresses challenges like file count quota limits, especially on supercomputing platforms. Furthermore, the format supports efficient parallel I/O on suitable hardware, making it ideal for scalable parallel data processing workflows.</p></li>
<li><p><strong>Versatile Data Type Support</strong>: Beyond seismograms, ASDF is adept at accommodating diverse data types prevalent in seismology. Whether it’s spectral estimations, cross-correlations, adjoint sources, receiver functions, or other data types, ASDF ensures organized, self-describing storage. This versatility ensures that seismologists can maintain a consistent data storage paradigm across various facets of their research.</p></li>
</ol>
<p>This format is particularly suited to meet the requirements of tomorrow.</p>
<h3 id="data-format-and-adaptation">Data Format and Adaptation</h3>
<p>The key is to ensure consistencies between the data and information to allow efficient cross-referencing, retrieval and usage.</p>
<p>In this section we will conver four types of data:</p>
<ul>
<li><strong>Waveforms</strong></li>
<li><strong>Catalog</strong></li>
<li><strong>Inventory/System</strong></li>
<li><strong>Grids</strong></li>
</ul>
<h3 id="waveform-data">Waveform Data</h3>
<p>The waveform data represents the raw vibrations recorded directly by the sensors. For convenience, waveform data can be provided in physical units native to the instrument recording the data of <span class="math inline"><em>m</em></span>, <span class="math inline"><em>m</em>/<em>s</em></span>​, or <span class="math inline"><em>m</em>/<em>s</em><sup>2</sup></span> for displacement, velocity, and acceleration, respectively. However, if size is a concern, storing the ADC counts as integers is more suitable. Storing the ADC count as integers allows for the more efficient use of compression algorithm and will allow the data to be more compact.</p>
<p>Alongside the amplitude values, additional metadata describing the instrument recording the data and time series parameters should be provided for each trace. Each trace should be stored with its own metadata information.</p>
<p>The required metadata for each trace includes:</p>
<ul>
<li><strong>Trace Identifier</strong>: A unique identifier for the trace (see Obspy <a href="https://docs.obspy.org/master/packages/autogen/obspy.core.event.resourceid.ResourceIdentifier.html">documentation</a> for information on the recommended <em>resource identifier</em> structure). The trace identifier format and convention should be normalized and align with the SEED naming convention including the standard part. Deviation regarding the naming shall, howerver, be permitted to allow longer names to be utilized.<br />
</li>
<li><strong>Location Identification</strong>: The location identification convention described <a href="https://ds.iris.edu/ds/newsletter/vol1/no1/1/specification-of-seismograms-the-location-identifier/">here</a>. This convention has been adapted for μseismic monitoring in the mining context.
<ul>
<li><strong>Network Code [network_code]</strong> — Code representing the network.</li>
<li><strong>Station Code [station_code]</strong> — Code representing the station containing the digitizer.</li>
<li><strong>Location Code [location_code]</strong> — Code representing the instrument.</li>
<li><strong>Channel Code [channel_code]</strong> — The three (3) alphanumerical code representing the channel shall follow the FDSN standard naming convention of August 2000 described in the SEED document <a href="http://www.fdsn.org/pdf/SEEDManual_V2.4_Appendix-A.pdf">Appendix A</a>. For instance, a typical 14 Hz or 15 Hz omnidirectional geophone code would be GH?, where ? would be replaced by the appropriate component orientation code.</li>
</ul></li>
<li><strong>Sampling Rate [sampling_rate]</strong> — The signal’s sampling rate in samples per second.</li>
<li><strong>Calibration Factor [calib]</strong> — This value is optional and defaults to 1.0 if not provided. It represents the calibration factor should the sensor deviate from the typical response.</li>
<li><strong>Start Time [starttime]</strong> — The trace’s start time.</li>
</ul>
<h4 id="notes">Notes:</h4>
<p><strong>Naming Convention</strong>: The full name of a component or channel is usually created as follows: <strong>channel name</strong> = <strong>network code</strong>.<strong>station code</strong>.<strong>location code</strong>.<strong>channel code</strong>.</p>
<p><strong>Network, Station, and Location Codes</strong>: The mentioned convention is often not strictly adhered to by μseismic system providers. Flexibility in applying the convention is crucial. Typically, no distinction is made between the station and location, and each instrument is assigned a unique code that may or may not refer to the data acquisition station. In such cases, we suggest using the <strong>Station Code</strong> field to store the <em>instrument</em> code and populate the location code with 01 or 00. In a network, each combination of <strong>Station Code</strong>.<strong>Location Code</strong>.<strong>Channel Code</strong> should be unique.</p>
<h4 id="suggested-naming-convention-and-usage">Suggested Naming Convention and Usage</h4>
<ul>
<li><strong>Network Code</strong>: The network code should represent a physical or logical network. A mine or mining complex can include multiple networks. The network name should be compact but be easily recognized and understood. For instance, the Oyu Tolgoi Hugo North Underground Lift 1 network can be represented by the following accronym: OTHNL1.</li>
<li><strong>Station Code</strong>: We recommend associating the station code to the location of a junction box where the data acquisition is talking place. The name should provide clear indication of where the JB is located within a mine. We suggest using the naming convention adopted at the operation. For example, assuming there are two junction box location in the Haulage Level Access Drive 2 referred to as HLAD2, the code for the two stations can be HLAD2_01 and HLAD2_02.</li>
<li><strong>Location Code</strong>: We suggest using the location code to refer to an instrument connected to a station.</li>
</ul>
<h3 id="catalog">Catalog</h3>
<p>The catalog includes information related to an event, a trigger, or a series of events. We suggest storing the catalog information in a QuakeML-like format adapted to μseismic data (see QuakeML <a href="https://quake.ethz.ch/quakeml">documentation</a>). The suggested changes affect the following QuakeML objects:</p>
<ul>
<li><strong>Event</strong> — The event_type field is restricted to specific values that are not suited for μseismic monitoring.</li>
<li><strong>Origin</strong> — The position is expressed in latitude and longitude. This will need to be changed to x, y, and z.</li>
<li><strong>Magnitude</strong> — The magnitude object would benefit from adding fields to store the corner frequency, as well as P-wave and S-wave Energy. This allows for a broad range of source parameters to be computed on the fly, rather than stored in the magnitude object. This approach is typically used in mine seismology.</li>
</ul>
<h4 id="event-event-type">Event — Event Type</h4>
<p>There are two approaches to modifying the event types:</p>
<ol type="1">
<li>Redefine the schema and allow for event types related to mining to be stored in a μQuakeML file; and</li>
<li>Map each μseismic type to an existing QuakeML event type.</li>
</ol>
<table>
<thead>
<tr class="header">
<th>Event Type (μseismic)</th>
<th>Event Type (QuakeML)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>earthquake/large event</td>
<td>earthquake</td>
</tr>
<tr class="even">
<td>seismic event</td>
<td>induced or triggered event</td>
</tr>
<tr class="odd">
<td>offsite event</td>
<td>atmospheric event</td>
</tr>
<tr class="even">
<td>rock burst</td>
<td>rock burst</td>
</tr>
<tr class="odd">
<td>fall of ground/rockfall</td>
<td>cavity collapse</td>
</tr>
<tr class="even">
<td>blast</td>
<td>explosion</td>
</tr>
<tr class="odd">
<td>blast sequence</td>
<td>accidental explosion</td>
</tr>
<tr class="even">
<td>development blast</td>
<td>industrial explosion</td>
</tr>
<tr class="odd">
<td>production blast</td>
<td>mining explosion</td>
</tr>
<tr class="even">
<td>far away blast/open pit blast</td>
<td>quarry blast</td>
</tr>
<tr class="odd">
<td>offsite blast</td>
<td>nuclear explosion</td>
</tr>
<tr class="even">
<td>paste firing</td>
<td>chemical explosion</td>
</tr>
<tr class="odd">
<td>calibration blast</td>
<td>controlled explosion</td>
</tr>
<tr class="even">
<td>other blast/slashing</td>
<td>experimental explosion</td>
</tr>
<tr class="odd">
<td>mid-shift blast/slash blast</td>
<td>industrial explosion</td>
</tr>
<tr class="even">
<td>raise bore</td>
<td>hydroacoustic event</td>
</tr>
<tr class="odd">
<td>crusher noise</td>
<td>road cut</td>
</tr>
<tr class="even">
<td>orepass noise</td>
<td>collapse</td>
</tr>
<tr class="odd">
<td>drilling noise</td>
<td>acoustic noise</td>
</tr>
<tr class="even">
<td>electrical noise</td>
<td>thunder</td>
</tr>
<tr class="odd">
<td>scaling noise</td>
<td>anthropogenic event</td>
</tr>
<tr class="even">
<td>mechanical noise</td>
<td>crash</td>
</tr>
<tr class="odd">
<td>test pulse</td>
<td>sonic boom</td>
</tr>
<tr class="even">
<td>unidentified noise/other noise</td>
<td>other event</td>
</tr>
<tr class="odd">
<td>duplicate</td>
<td>boat crash</td>
</tr>
<tr class="even">
<td>unknown</td>
<td>plane crash</td>
</tr>
<tr class="odd">
<td>tap test/test</td>
<td>avalanche</td>
</tr>
</tbody>
</table>
<p>The above mapping is implemented in the μQuake library.</p>
<h4 id="origin-coordinate-system">Origin — Coordinate System</h4>
<p>The QuakeML format was designed to store seismic data at a regional and global scale. Consequently, the QuakeML format has adopted a spherical coordinate system, storing location information in latitude and longitude.</p>
<p>Using latitude and longitude to describe mining-related events is possible but not convenient. It would require precisely knowing the series of transformations needed to convert the position expressed in the local coordinate system into longitude and latitude. We suggest overriding the latitude and longitude information and using x, y, and z instead. The use of x, y, and z notation, as opposed to the right-handed (easting, northing, and elevation) or (northing, easting, down) triplets, is to provide flexible notation and ensure consistency between the mine and the seismic system’s coordinate systems.</p>
<p>The μQuake implementation exploits the QuakeML extra parameters to store the x, y, and z values and associated errors.</p>
<h4 id="magnitude-corner-frequency-and-energy">Magnitude — Corner Frequency, and Energy</h4>
<p>The QuakeML standard does not include objects suited to store the corner frequency. The energy could be stored in the amplitude or station_magnitude object. However, this isn’t convenient, as it’s preferable for the magnitude and energy information to be used in tandem.</p>
<p>The μQuake implementation stores the <code>corner_frequency</code>, the <code>energy_p</code>, <code>energy_s</code>, and associated error alongside the magnitude information in the extra parameter of the Magnitude object.</p>
<h3 id="system-or-inventory-information">System or Inventory Information</h3>
<p>The system or inventory information is crucial for any seismic network as it provides comprehensive details about the stations and channels that are a part of that network. The StationXML format, which is an established standard in the seismic community, is designed to hold such inventory metadata.</p>
<p>However, when tailoring the use of StationXML to the μseismic domain, especially in the mining context, certain modifications are required to better fit the data’s unique characteristics and requirements.</p>
<h4 id="station-channel-coordinates">Station &amp; Channel Coordinates</h4>
<p>In a typical seismic application, the StationXML format uses latitude and longitude to describe the geographical position of stations and channels. While this makes sense for global and regional seismic networks, it’s not as intuitive or convenient for the μseismic monitoring within a mining setup. In such a scenario, the geographical location is often best described using a local coordinate system.</p>
<p>Thus, we recommend replacing the latitude and longitude fields in the StationXML format with <code>x</code>, <code>y</code>, and <code>z</code> coordinates for both the station and channel locations. This change aligns with the earlier modifications made for QuakeML, ensuring consistency across different components of the μseismic system.</p>
<h3 id="system-metadata-and-grid-data">System Metadata and Grid Data</h3>
<p>To fully enable the interpretation of the seismic data, accessing information on the velocity models is essential. Other important although not as essential are the attenuation model if they exist and the density values or model. The velocity values/models are increasingly represented on a grid.</p>
<p>In this section, we propose using a simple grid format for data exchange.</p>
<h4 id="grid-format-overview">Grid Format Overview</h4>
<p>The grid format is structured to represent the velocity model in a systematic, gridded layout. It comprises two main components: the header, which contains metadata about the grid, and the grid values that reflect the actual data.</p>
<h5 id="header">Header</h5>
<p>The header is a crucial section that offers insights into the grid’s specifications, such as its dimensions, the starting point (origin) of the grid, and the intervals or spacings between grid points. A sample header in Python dictionary format might look like:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true"></a>header <span class="op">=</span> {</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true"></a>    <span class="st">&quot;NX&quot;</span>: <span class="dv">100</span>,            <span class="co"># Number of grid points in the X direction</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true"></a>    <span class="st">&quot;NY&quot;</span>: <span class="dv">100</span>,            <span class="co"># Number of grid points in the Y direction</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true"></a>    <span class="st">&quot;NZ&quot;</span>: <span class="dv">50</span>,             <span class="co"># Number of grid points in the Z direction</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true"></a>    <span class="st">&quot;ORIGX&quot;</span>: <span class="fl">0.0</span>,         <span class="co"># X coordinate of the grid origin</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true"></a>    <span class="st">&quot;ORIGY&quot;</span>: <span class="fl">0.0</span>,         <span class="co"># Y coordinate of the grid origin</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true"></a>    <span class="st">&quot;ORIGZ&quot;</span>: <span class="fl">0.0</span>,         <span class="co"># Z coordinate of the grid origin</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true"></a>    <span class="st">&quot;SPACEX&quot;</span>: <span class="fl">0.1</span>,        <span class="co"># Grid spacing in the X direction</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true"></a>    <span class="st">&quot;SPACEY&quot;</span>: <span class="fl">0.1</span>,        <span class="co"># Grid spacing in the Y direction</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true"></a>    <span class="st">&quot;SPACEZ&quot;</span>: <span class="fl">0.2</span>,        <span class="co"># Grid spacing in the Z direction</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true"></a>}</span></code></pre></div>
<p>This dictionary effectively captures the grid’s spatial boundaries, intervals, and the type of data contained.</p>
<h5 id="grid-data">Grid Data</h5>
<p>The grid data values follow the header. Organized in a sequence, they represent their positions within the grid. For simplicity and efficiency, these values can be represented as a 2D numpy array:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true"></a></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true"></a><span class="co"># For demonstration purposes, initializing a 2D array with NXxNYxNZ dimensions</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true"></a>grid_values <span class="op">=</span> np.zeros((header[<span class="st">&quot;NX&quot;</span>], header[<span class="st">&quot;NY&quot;</span>], header[<span class="st">&quot;NZ&quot;</span>]))</span></code></pre></div>
<p>In this representation, the grid values are stored in a structured manner, allowing for easy indexing and operations. Each cell in the array corresponds to a grid point in the velocity model, with its value representing the velocity (or density or attenuation, depending on the grid type) at that point.</p>
<h2 id="implementation-using-the-μquake-python-library">Implementation using the μQuake Python Library</h2>
<p>Within the context of this RFC, which proposes specific adaptations and formats tailored to microseismic monitoring, the <code>uquake</code> library stands as a practical implementation of these recommendations. Developed in Python and built upon ObsPy, <code>uquake</code> has been specially crafted to cater to the distinctive needs of microseismic monitoring in mining environments. This includes, amongst other capabilities, the handling of local coordinate systems and unique event types frequently observed in mine microseismic monitoring. For those seeking an immediate and tangible application of the proposed data format recommendations from this RFC, <code>uquake</code> offers a ready solution. It is open source, distributed under AGPL license and publicly available and can be easily accessed and installed via pip using <code>pip install uquake</code>.</p>
<p>Note that there are alternative libraries addressing the same issues μQuake tackles. The author is, howerver, less familiar with the alternatives. Notable alternatives are</p>
<p>The Niosh <a href="https://github.com/niosh-mining/obsplus">Obsplus</a> <a href="https://github.com/DASDAE/dascore">DASCORE</a></p>
<h3 id="implementation-using-uquake">Implementation using <code>uquake</code></h3>
<p>The <code>uquake</code> library provides the necessary tools to handle gridded data in seismology. One of the primary objects to manage such grid data is the <code>Grid</code> class from <code>uquake.core.grid.base</code>. This class is designed to hold regular grids and can be employed for both 2D and 3D data structures.</p>
<h4 id="initializing-a-grid">Initializing a Grid</h4>
<p>The <code>Grid</code> object can be initialized using either a numpy array representing the grid data or by specifying the grid dimensions. When using the latter approach, the grid is initialized with a default or specified value.</p>
<p>Let’s consider a simple example to illustrate this:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true"></a><span class="im">from</span> uquake.core.grid.base <span class="im">import</span> Grid</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true"></a></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true"></a><span class="co"># Define grid header specifications</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true"></a></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true"></a>header <span class="op">=</span> {</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true"></a>    <span class="st">&quot;NX&quot;</span>: <span class="dv">100</span>,  </span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true"></a>    <span class="st">&quot;NY&quot;</span>: <span class="dv">100</span>,  </span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true"></a>    <span class="st">&quot;NZ&quot;</span>: <span class="dv">50</span>,   </span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true"></a>    <span class="st">&quot;ORIGX&quot;</span>: <span class="fl">0.0</span>,  </span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true"></a>    <span class="st">&quot;ORIGY&quot;</span>: <span class="fl">0.0</span>,  </span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true"></a>    <span class="st">&quot;ORIGZ&quot;</span>: <span class="fl">0.0</span>,  </span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true"></a>    <span class="st">&quot;SPACEX&quot;</span>: <span class="fl">0.1</span>,  </span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true"></a>    <span class="st">&quot;SPACEY&quot;</span>: <span class="fl">0.1</span>,  </span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true"></a>    <span class="st">&quot;SPACEZ&quot;</span>: <span class="fl">0.2</span>,  </span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true"></a>}</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true"></a></span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true"></a><span class="co"># Initialize the grid using grid dimensions and set default value as 0</span></span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true"></a></span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true"></a>grid_dims <span class="op">=</span> (header[<span class="st">&quot;NX&quot;</span>], header[<span class="st">&quot;NY&quot;</span>], header[<span class="st">&quot;NZ&quot;</span>])</span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true"></a>spacing <span class="op">=</span> (header[<span class="st">&quot;SPACEX&quot;</span>], header[<span class="st">&quot;SPACEY&quot;</span>], header[<span class="st">&quot;SPACEZ&quot;</span>])</span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true"></a>origin <span class="op">=</span> (header[<span class="st">&quot;ORIGX&quot;</span>], header[<span class="st">&quot;ORIGY&quot;</span>], header[<span class="st">&quot;ORIGZ&quot;</span>])</span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true"></a></span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true"></a>grid <span class="op">=</span> Grid(data_or_dims<span class="op">=</span>grid_dims, spacing<span class="op">=</span>spacing, origin<span class="op">=</span>origin, value<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true"></a></span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true"></a><span class="co"># Write the modified or new grid to a file</span></span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true"></a>grid.write(<span class="st">&quot;path_to_new_grid_file.grid&quot;</span>)</span></code></pre></div>
<p>Here, we’ve initialized a 3D grid using the dimensions specified in the header. The grid is filled with a default value of 0.</p>
<h4 id="reading-and-writing-grids">Reading and Writing Grids</h4>
<p>The <code>Grid</code> object is equipped with methods to read and write grid data, making it easy to load existing grids or store newly created or modified grids.</p>
<p>Here’s an example of how one might read from and write to a grid file:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true"></a><span class="co"># all versions</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true"></a><span class="im">from</span> uquake.core.grid <span class="im">import</span> read_grid</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true"></a></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true"></a><span class="co"># Reading a grid from a file</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true"></a>grid_from_file <span class="op">=</span> Grid.read(<span class="st">&quot;path_to_grid_file.grid&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb5"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true"></a><span class="co"># from version 2.0.1</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true"></a><span class="co"># Reading a grid from a file</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true"></a>grid_from_file <span class="op">=</span> Grid.read(<span class="st">&quot;path_to_grid_file.grid&quot;</span>) </span></code></pre></div>
<p>This approach simplifies the process of handling gridded data in seismology by using the <code>uquake</code> library’s built-in functionalities.</p>
<h2 id="rationale-1">Rationale</h2>
<p>Understanding the motivations and reasons behind any proposed change is essential to ensure clarity, gain stakeholder buy-in, and ensure the technical merits of the proposal align with the broader goals.</p>
<ol type="1">
<li><p><strong>Choice of Data Packaging Formats</strong>: The decision to employ ASDF for the encapsulation of both catalog information and waveform data, combined with the inherent XML structure for QuakeML, is rooted in their respective proficiencies and widespread acceptance within the industry. ASDF provides an efficient mechanism for storing and fetching data, especially when dealing with substantial datasets. Concurrently, the integral XML structure guarantees interoperability with systems customarily developed for QuakeML processing.</p></li>
<li><p><strong>Adapting QuakeML for μseismic Data</strong>: Traditional QuakeML formats, while robust for standard seismology needs, are not fully suited to address the nuances of μseismic data. The unique requirements of μseismic monitoring, especially in mining contexts, necessitate modifications to the existing format. By making these adjustments, the system becomes more flexible and directly applicable to the μseismic domain, allowing for better data representation and interpretation.</p></li>
<li><p><strong>Use of a Grid for Velocity Models</strong>: Seismic data interpretation largely hinges on the accuracy and clarity of velocity models. The industry trend has shifted towards grid representations of these models due to their higher precision and ease of use. Implementing a standard grid format for data exchange promotes interoperability and standardization across systems and tools.</p></li>
<li><p><strong>Introduction of the <code>uquake</code> Library</strong>: The seismic domain has various software libraries that cater to specific needs. The choice of <code>uquake</code> was driven by its capabilities to manage the proposed data structures efficiently and its extensibility to cater to future modifications. By embedding support for the newly proposed data structures directly within <code>uquake</code>, users can expect a seamless experience and avoid the complexities associated with multi-tool workflows.</p></li>
<li><p><strong>Latitude and Longitude to X, Y, Z Conversion</strong>: Given that most mining operations work on local coordinate systems rather than global ones, expressing positions in terms of x, y, and z becomes not just convenient, but also essential. This shift eliminates the need for complex transformations and ensures data is immediately useful for local operations and analysis.</p></li>
</ol>
<p>In summary, the proposed changes and implementations in this RFC stem from a direct need to address the unique challenges posed by μseismic monitoring, especially in mining contexts. They reflect both the evolution of seismic data interpretation methodologies and the tools used in the industry. Through these proposals, we aim to establish a more streamlined, precise, and standardized approach to μseismic data management and interpretation.</p>
<h3 id="feedback-mechanism">Feedback Mechanism</h3>
<p>Feedback and contributions from the community are essential to refining and improving this RFC. There are two primary ways through which stakeholders, developers, and interested parties can provide their feedback:</p>
<ol type="1">
<li><p><strong>GitHub Issues</strong>:</p>
<ul>
<li>Navigate to the <a href="https://github.com/Microquake-ai/RFC-micro-seismic-data-exchange-format/tree/main">RFC micro-seismic data exchange format repository on GitHub</a>.</li>
<li>Go to the <code>Issues</code> tab.</li>
<li>Click on <code>New Issue</code> to create a new issue.</li>
<li>Provide a concise title and detailed description of your feedback, suggestions, or concerns.</li>
<li>Once submitted, the issue will be visible to the community, and the project maintainers will review and address it as appropriate.</li>
</ul></li>
<li><p><strong>Email</strong>:</p>
<ul>
<li>If you prefer a more direct approach or have feedback that you’d like to keep private, you can send an email to <a href="mailto:rfc_format@microquake.ai">rfc_format@microquake.ai</a>.</li>
<li>Please provide a clear subject line relevant to your feedback to ensure swift handling of your email.</li>
<li>While we appreciate all feedback, do note that due to the volume of emails, it might take some time before you receive a response.</li>
</ul></li>
</ol>
<p>Whether you choose to leave an issue on GitHub or send an email, your feedback is invaluable. It aids in ensuring that the proposed micro-seismic data exchange format is robust, relevant, and addresses the needs of the community.</p>
<p>Thank you for taking the time to review this RFC and for your contributions towards its continual improvement.</p>
<h2 id="references">References</h2>
<p>Krischer, L., Smith, J. A., Lei, W., Lefebvre, M., Ruan, Y., &amp; Tromp, J. (2016). An Adaptable Seismic Data Format. Geophysical Journal International, 207(2), 1003–1011. <a href="https://academic.oup.com/gji/article/207/2/1003/2583765">Link</a></p>
<!--stackedit_data:
eyJoaXN0b3J5IjpbLTEwOTA5MTI2MzcsNzU2NTkxOTA5LDYyMT
YxNjQwMSwxODEwNjY4NTM2LDcxOTYzMzA5NSwxMzM5MzUwMTMs
LTIxNDU0ODU0MjEsLTE4NzM2NDI4MjQsLTgwMzQxNzQ4NCwtMT
EyNDU5OTkzOSwxNDI5MTkyOTI2LDI5MTY4OTEzNiwxOTk0NDk1
NjMyLC02NDIyMTgxMjMsOTg2OTUxNjc2LC0xMjg4MTMxNjksLT
M4OTQzNTk5MywtNzU0MzcxODE5LC0xOTg3MDQzMDk5LC0xOTQ1
NzI3ODU4XX0=
-->
